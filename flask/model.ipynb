{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, Model, Sequential\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/career_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:49,:-1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"Suggested Job Role\"]\n",
    "labels_unique = labels.unique().tolist()\n",
    "labels = labels.map(lambda x: labels_unique.index(x))\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = {}\n",
    "k[\"certification\"]=df[\"certifications\"].unique().tolist()\n",
    "k[\"workshops\"]=df[\"workshops\"].unique().tolist()\n",
    "k[\"Interested subjects\"]=df[\"Interested subjects\"].unique().tolist()\n",
    "k[\"interested career area\"]=df[\"interested career area \"].unique().tolist()\n",
    "k['Type of company want to settle in?']=df['Type of company want to settle in?'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion = [\n",
    "    'Hours working per day',\n",
    "    'Logical quotient rating',\n",
    "    'hackathons',\n",
    "    'coding skills rating',\n",
    "    'public speaking points']\n",
    "\n",
    "items_1 = [\n",
    "    'Acedamic percentage in Operating Systems', \n",
    "    'percentage in Algorithms',\n",
    "    'Percentage in Programming Concepts',\n",
    "    'Percentage in Software Engineering', \n",
    "    'Percentage in Computer Networks',\n",
    "    'Percentage in Electronics Subjects',\n",
    "    'Percentage in Computer Architecture', \n",
    "    'Percentage in Mathematics',\n",
    "    'Percentage in Communication skills']\n",
    "\n",
    "items_2 = [\n",
    "    'can work long time before system?',\n",
    "    'self-learning capability?', \n",
    "    'Extra-courses did',\n",
    "    'Management or Technical', \n",
    "    'Salary/work', \n",
    "    'hard/smart worker', \n",
    "    'worked in teams ever?', \n",
    "    'Introvert', \n",
    "    'Job/Higher Studies?']\n",
    "\n",
    "items_3 = [\n",
    "    'certifications',\n",
    "    'workshops',\n",
    "    'reading and writing skills',\n",
    "    'memory capability score',\n",
    "    'Interested subjects',\n",
    "    'interested career area ',\n",
    "    'Type of company want to settle in?']\n",
    "\n",
    "print(items_1+items_2+items_3+exclusion)\n",
    "\n",
    "def convert_to_x(row):\n",
    "    global df\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for col in row.index:\n",
    "        if col in items_1:\n",
    "            labels.append(row[col]/100)\n",
    "        elif col in items_2:\n",
    "            labels.append(0 if row[col] == \"no\" else 1)\n",
    "        elif col in items_3:\n",
    "            uniques = df[col].unique().tolist()\n",
    "            labels.append(uniques.index(row[col]))\n",
    "        elif col in exclusion:\n",
    "            labels.append(row[col])\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([convert_to_x(df.iloc[i]) for i in tqdm(df.index)])\n",
    "np.save(\"./dataset/xs.npy\", xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.load(\"./dataset/xs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_list(l, group_size):\n",
    "    for i in range(0, len(l), group_size):\n",
    "        yield l[i:i+group_size]\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "split_at = int(len(xs)//BATCH_SIZE * 0.8)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((xs, labels)).shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "train_dataset = dataset.take(split_at)\n",
    "test_dataset = dataset.skip(split_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_items = len(items_1) + len(items_2) + len(items_3) + len(exclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    _input = layers.Input(shape=(sum_items,))\n",
    "\n",
    "    a, b, c, d = tf.split(_input, [len(items_1), len(items_2), len(items_3), len(exclusion)], axis=1)\n",
    "\n",
    "    e1 = layers.Dense(32, activation=\"relu\")(a)\n",
    "    # # e1 = layers.LeakyReLU(0.2)(e1)\n",
    "    e2 = layers.Dense(32, activation=\"relu\")(b)\n",
    "    # # e1 = layers.LeakyReLU(0.2)(e1)\n",
    "    e3 = layers.Dense(32, activation=\"relu\")(c)\n",
    "    # # e1 = layers.LeakyReLU(0.2)(e1)\n",
    "    e4 = layers.Dense(32, activation=\"relu\")(d)\n",
    "    # e4 = layers.LeakyReLU(0.2)(e4)\n",
    "\n",
    "    e = layers.concatenate([e1, e2, e3, e4])\n",
    "    # e = layers.Dropout(0.2)(e)\n",
    "    # e = layers.LayerNormalization()(e)\n",
    "\n",
    "    # use multihead attention\n",
    "    attention = layers.MultiHeadAttention(num_heads=8, key_dim=8, attention_axes=(1,))(_input, _input)\n",
    "    # attention = layers.LayerNormalization()(attention)\n",
    "\n",
    "    e = layers.Dense(1024, activation=\"relu\")(e)\n",
    "    e = layers.Dropout(0.2)(e)\n",
    "    e = layers.Dense(1024, activation=\"relu\")(e)\n",
    "    e = layers.Dropout(0.2)(e)\n",
    "    e = layers.Dense(512, activation=\"relu\")(e)\n",
    "    e = layers.Dropout(0.2)(e)\n",
    "    e = layers.Dense(256, activation=\"relu\")(e)\n",
    "    e = layers.Dense(labels.shape[-1], activation=\"softmax\")(e)\n",
    "\n",
    "    return Model(inputs=[_input], outputs=e)\n",
    "\n",
    "model = make_model()\n",
    "model.compile(\n",
    "    # optimizer=keras.optimizers.Adam(learning_rate=0.0001, epsilon=1e-07),\n",
    "    optimizer=keras.optimizers.Adagrad(learning_rate=0.01),\n",
    "    # optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"categorical_accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_31\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_41 (InputLayer)          [(None, 31)]         0           []                               \n",
      "                                                                                                  \n",
      " tf.split_29 (TFOpLambda)       [(None, 9),          0           ['input_41[0][0]']               \n",
      "                                 (None, 9),                                                       \n",
      "                                 (None, 8),                                                       \n",
      "                                 (None, 5)]                                                       \n",
      "                                                                                                  \n",
      " dense_256 (Dense)              (None, 32)           320         ['tf.split_29[0][0]']            \n",
      "                                                                                                  \n",
      " dense_257 (Dense)              (None, 32)           320         ['tf.split_29[0][1]']            \n",
      "                                                                                                  \n",
      " dense_258 (Dense)              (None, 32)           288         ['tf.split_29[0][2]']            \n",
      "                                                                                                  \n",
      " dense_259 (Dense)              (None, 32)           192         ['tf.split_29[0][3]']            \n",
      "                                                                                                  \n",
      " concatenate_30 (Concatenate)   (None, 128)          0           ['dense_256[0][0]',              \n",
      "                                                                  'dense_257[0][0]',              \n",
      "                                                                  'dense_258[0][0]',              \n",
      "                                                                  'dense_259[0][0]']              \n",
      "                                                                                                  \n",
      " dense_260 (Dense)              (None, 1024)         132096      ['concatenate_30[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_72 (Dropout)           (None, 1024)         0           ['dense_260[0][0]']              \n",
      "                                                                                                  \n",
      " dense_261 (Dense)              (None, 1024)         1049600     ['dropout_72[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_73 (Dropout)           (None, 1024)         0           ['dense_261[0][0]']              \n",
      "                                                                                                  \n",
      " dense_262 (Dense)              (None, 512)          524800      ['dropout_73[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)           (None, 512)          0           ['dense_262[0][0]']              \n",
      "                                                                                                  \n",
      " dense_263 (Dense)              (None, 256)          131328      ['dropout_74[0][0]']             \n",
      "                                                                                                  \n",
      " dense_264 (Dense)              (None, 34)           8738        ['dense_263[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,847,682\n",
      "Trainable params: 1,847,682\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/main.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "    0.82,0.81,0.85,0.78,0.80,0.70,0.80,0.91,0.81,\n",
    "    10,8,3,8,6,\n",
    "    1,1,1,\n",
    "    1,3,0,1,\n",
    "    2,2,7,2,\n",
    "    0,8,0,1,29,0,\n",
    "    1,1,1,1,1,1,1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model(np.expand_dims(np.array(x), axis=0)).numpy() * 100)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_unique[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.expand_dims(np.array(convert_to_x(df.iloc[1000])), axis=0)\n",
    "labels[1000].tolist().index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"interested career area \"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "063da5ec96525b703b2b4b88ba5015678e29341c0c783b18b72decb99d23a1d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
