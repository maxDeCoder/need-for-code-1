{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, Model, Sequential\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/career_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Acedamic percentage in Operating Systems', 'percentage in Algorithms',\n",
       "       'Percentage in Programming Concepts',\n",
       "       'Percentage in Software Engineering', 'Percentage in Computer Networks',\n",
       "       'Percentage in Electronics Subjects',\n",
       "       'Percentage in Computer Architecture', 'Percentage in Mathematics',\n",
       "       'Percentage in Communication skills', 'Hours working per day',\n",
       "       'Logical quotient rating', 'hackathons', 'coding skills rating',\n",
       "       'public speaking points', 'can work long time before system?',\n",
       "       'self-learning capability?', 'Extra-courses did', 'certifications',\n",
       "       'workshops', 'talenttests taken?', 'olympiads',\n",
       "       'reading and writing skills', 'memory capability score',\n",
       "       'Interested subjects', 'interested career area ', 'Job/Higher Studies?',\n",
       "       'Type of company want to settle in?',\n",
       "       'Taken inputs from seniors or elders', 'interested in games',\n",
       "       'Interested Type of Books', 'Salary Range Expected',\n",
       "       'In a Realtionship?', 'Gentle or Tuff behaviour?',\n",
       "       'Management or Technical', 'Salary/work', 'hard/smart worker',\n",
       "       'worked in teams ever?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:49,:-1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"Suggested Job Role\"]\n",
    "labels_unique = labels.unique().tolist()\n",
    "labels = labels.map(lambda x: labels_unique.index(x))\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = {}\n",
    "k[\"certification\"]=df[\"certifications\"].unique().tolist()\n",
    "k[\"workshops\"]=df[\"workshops\"].unique().tolist()\n",
    "k[\"Interested subjects\"]=df[\"Interested subjects\"].unique().tolist()\n",
    "k[\"interested career area\"]=df[\"interested career area \"].unique().tolist()\n",
    "k['Type of company want to settle in?']=df['Type of company want to settle in?'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'certification': ['shell programming',\n",
       "  'machine learning',\n",
       "  'app development',\n",
       "  'python',\n",
       "  'r programming',\n",
       "  'information security',\n",
       "  'hadoop',\n",
       "  'distro making',\n",
       "  'full stack'],\n",
       " 'workshops': ['cloud computing',\n",
       "  'database security',\n",
       "  'web technologies',\n",
       "  'data science',\n",
       "  'testing',\n",
       "  'hacking',\n",
       "  'game development',\n",
       "  'system designing'],\n",
       " 'Interested subjects': ['cloud computing',\n",
       "  'networks',\n",
       "  'hacking',\n",
       "  'Computer Architecture',\n",
       "  'programming',\n",
       "  'parallel computing',\n",
       "  'IOT',\n",
       "  'data engineering',\n",
       "  'Software Engineering',\n",
       "  'Management'],\n",
       " 'interested career area': ['system developer',\n",
       "  'Business process analyst',\n",
       "  'developer',\n",
       "  'testing',\n",
       "  'security',\n",
       "  'cloud computing'],\n",
       " 'Type of company want to settle in?': ['Web Services',\n",
       "  'SAaS services',\n",
       "  'Sales and Marketing',\n",
       "  'Testing and Maintainance Services',\n",
       "  'product development',\n",
       "  'BPA',\n",
       "  'Service Based',\n",
       "  'Product based',\n",
       "  'Cloud Services',\n",
       "  'Finance']}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion = [\n",
    "    'Hours working per day',\n",
    "    'Logical quotient rating',\n",
    "    'hackathons',\n",
    "    'coding skills rating',\n",
    "    'public speaking points']\n",
    "\n",
    "items_1 = [\n",
    "    'Acedamic percentage in Operating Systems', \n",
    "    'percentage in Algorithms',\n",
    "    'Percentage in Programming Concepts',\n",
    "    'Percentage in Software Engineering', \n",
    "    'Percentage in Computer Networks',\n",
    "    'Percentage in Electronics Subjects',\n",
    "    'Percentage in Computer Architecture', \n",
    "    'Percentage in Mathematics',\n",
    "    'Percentage in Communication skills']\n",
    "\n",
    "items_2 = [\n",
    "    'can work long time before system?',\n",
    "    'self-learning capability?', \n",
    "    'Extra-courses did',\n",
    "    'Management or Technical', \n",
    "    'Salary/work', \n",
    "    'hard/smart worker', \n",
    "    'worked in teams ever?', \n",
    "    'Introvert', \n",
    "    'Job/Higher Studies?']\n",
    "\n",
    "items_3 = [\n",
    "    'certifications',\n",
    "    'workshops',\n",
    "    'reading and writing skills',\n",
    "    'memory capability score',\n",
    "    'Interested subjects',\n",
    "    'interested career area ',\n",
    "    'Type of company want to settle in?']\n",
    "\n",
    "print(items_1+items_2+items_3+exclusion)\n",
    "\n",
    "def convert_to_x(row):\n",
    "    global df\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for col in row.index:\n",
    "        if col in items_1:\n",
    "            labels.append(row[col]/100)\n",
    "        elif col in items_2:\n",
    "            labels.append(0 if row[col] == \"no\" else 1)\n",
    "        elif col in items_3:\n",
    "            uniques = df[col].unique().tolist()\n",
    "            labels.append(uniques.index(row[col]))\n",
    "        elif col in exclusion:\n",
    "            labels.append(row[col])\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Acedamic percentage in Operating Systems', 'percentage in Algorithms',\n",
       "       'Percentage in Programming Concepts',\n",
       "       'Percentage in Software Engineering', 'Percentage in Computer Networks',\n",
       "       'Percentage in Electronics Subjects',\n",
       "       'Percentage in Computer Architecture', 'Percentage in Mathematics',\n",
       "       'Percentage in Communication skills', 'Hours working per day',\n",
       "       'Logical quotient rating', 'hackathons', 'coding skills rating',\n",
       "       'public speaking points', 'can work long time before system?',\n",
       "       'self-learning capability?', 'Extra-courses did', 'certifications',\n",
       "       'workshops', 'talenttests taken?', 'olympiads',\n",
       "       'reading and writing skills', 'memory capability score',\n",
       "       'Interested subjects', 'interested career area ', 'Job/Higher Studies?',\n",
       "       'Type of company want to settle in?',\n",
       "       'Taken inputs from seniors or elders', 'interested in games',\n",
       "       'Interested Type of Books', 'Salary Range Expected',\n",
       "       'In a Realtionship?', 'Gentle or Tuff behaviour?',\n",
       "       'Management or Technical', 'Salary/work', 'hard/smart worker',\n",
       "       'worked in teams ever?', 'Introvert'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [03:20<00:00, 99.98it/s] \n"
     ]
    }
   ],
   "source": [
    "xs = np.array([convert_to_x(df.iloc[i]) for i in tqdm(df.index)])\n",
    "np.save(\"./dataset/xs.npy\", xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.load(\"./dataset/xs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_list(l, group_size):\n",
    "    for i in range(0, len(l), group_size):\n",
    "        yield l[i:i+group_size]\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "split_at = int(len(xs)//BATCH_SIZE * 0.8)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((xs, labels)).shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "train_dataset = dataset.take(split_at)\n",
    "test_dataset = dataset.skip(split_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_items = len(items_1) + len(items_2) + len(items_3) + len(exclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    _input = layers.Input(shape=(sum_items,))\n",
    "\n",
    "    a, b, c, d = tf.split(_input, [len(items_1), len(items_2), len(items_3), len(exclusion)], axis=1)\n",
    "\n",
    "    e1 = layers.Dense(32, activation=\"relu\")(a)\n",
    "    # # e1 = layers.LeakyReLU(0.2)(e1)\n",
    "    e2 = layers.Dense(32, activation=\"relu\")(b)\n",
    "    # # e1 = layers.LeakyReLU(0.2)(e1)\n",
    "    e3 = layers.Dense(32, activation=\"relu\")(c)\n",
    "    # # e1 = layers.LeakyReLU(0.2)(e1)\n",
    "    e4 = layers.Dense(32, activation=\"relu\")(d)\n",
    "    # e4 = layers.LeakyReLU(0.2)(e4)\n",
    "\n",
    "    e = layers.concatenate([e1, e2, e3, e4])\n",
    "    # e = layers.Dropout(0.2)(e)\n",
    "    # e = layers.LayerNormalization()(e)\n",
    "\n",
    "    # use multihead attention\n",
    "    attention = layers.MultiHeadAttention(num_heads=8, key_dim=8, attention_axes=(1,))(_input, _input)\n",
    "    # attention = layers.LayerNormalization()(attention)\n",
    "\n",
    "    e = layers.Dense(1024, activation=\"relu\")(e)\n",
    "    e = layers.Dropout(0.2)(e)\n",
    "    e = layers.Dense(1024, activation=\"relu\")(e)\n",
    "    e = layers.Dropout(0.2)(e)\n",
    "    e = layers.Dense(512, activation=\"relu\")(e)\n",
    "    e = layers.Dropout(0.2)(e)\n",
    "    e = layers.Dense(256, activation=\"relu\")(e)\n",
    "    e = layers.Dense(labels.shape[-1], activation=\"softmax\")(e)\n",
    "\n",
    "    return Model(inputs=[_input], outputs=e)\n",
    "\n",
    "model = make_model()\n",
    "model.compile(\n",
    "    # optimizer=keras.optimizers.Adam(learning_rate=0.0001, epsilon=1e-07),\n",
    "    optimizer=keras.optimizers.Adagrad(learning_rate=0.01),\n",
    "    # optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"categorical_accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 0.3903 - categorical_accuracy: 0.8844 - val_loss: 5.4808 - val_categorical_accuracy: 0.2280\n",
      "Epoch 2/1000\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.3783 - categorical_accuracy: 0.8898 - val_loss: 5.4986 - val_categorical_accuracy: 0.2278_accuracy: 0.\n",
      "Epoch 3/1000\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.3769 - categorical_accuracy: 0.8873 - val_loss: 5.5024 - val_categorical_accuracy: 0.2253\n",
      "Epoch 4/1000\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.3841 - categorical_accuracy: 0.8843 - val_loss: 5.5069 - val_categorical_accuracy: 0.2295\n",
      "Epoch 5/1000\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.3753 - categorical_accuracy: 0.8889 - val_loss: 5.5155 - val_categorical_accuracy: 0.2262\n",
      "Epoch 6/1000\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.3822 - categorical_accuracy: 0.8857 - val_loss: 5.5007 - val_categorical_accuracy: 0.2292\n",
      "Epoch 7/1000\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.3914 - categorical_accuracy: 0.8796 - val_loss: 5.4982 - val_categorical_accuracy: 0.2280\n",
      "Epoch 8/1000\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.3819 - categorical_accuracy: 0.8860 - val_loss: 5.4993 - val_categorical_accuracy: 0.2260\n",
      "Epoch 9/1000\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.3756 - categorical_accuracy: 0.8887 - val_loss: 5.4901 - val_categorical_accuracy: 0.2278\n",
      "Epoch 10/1000\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.3782 - categorical_accuracy: 0.8879 - val_loss: 5.4854 - val_categorical_accuracy: 0.2278\n",
      "Epoch 11/1000\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.3763 - categorical_accuracy: 0.8898 - val_loss: 5.4841 - val_categorical_accuracy: 0.2275\n",
      "Epoch 12/1000\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.3688 - categorical_accuracy: 0.8883 - val_loss: 5.5327 - val_categorical_accuracy: 0.2253\n",
      "Epoch 13/1000\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.3704 - categorical_accuracy: 0.8882 - val_loss: 5.5316 - val_categorical_accuracy: 0.2307\n",
      "Epoch 14/1000\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.3618 - categorical_accuracy: 0.8937 - val_loss: 5.5364 - val_categorical_accuracy: 0.2313\n",
      "Epoch 15/1000\n",
      " 51/160 [========>.....................] - ETA: 1s - loss: 0.3460 - categorical_accuracy: 0.8959"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4828/3261758552.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "    0.82,0.81,0.85,0.78,0.80,0.70,0.80,0.91,0.81,\n",
    "    10,8,3,8,6,\n",
    "    1,1,1,\n",
    "    1,3,0,1,\n",
    "    2,2,7,2,\n",
    "    0,8,0,1,29,0,\n",
    "    1,1,1,1,1,1,1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.510838508605957,\n",
       " 0.009297593496739864,\n",
       " 0.006974688731133938,\n",
       " 0.07236986607313156,\n",
       " 1.9401112794876099,\n",
       " 0.9470861554145813,\n",
       " 4.636445045471191,\n",
       " 6.032196521759033,\n",
       " 0.14621862769126892,\n",
       " 0.1669691503047943,\n",
       " 13.264496803283691,\n",
       " 0.17827068269252777,\n",
       " 0.0003387811593711376,\n",
       " 0.08490696549415588,\n",
       " 0.12952132523059845,\n",
       " 0.000183049138286151,\n",
       " 0.6904901266098022,\n",
       " 9.815388693823479e-06,\n",
       " 33.59199523925781,\n",
       " 0.026268435642123222,\n",
       " 0.9199110865592957,\n",
       " 0.0011916409712284803,\n",
       " 0.06737217307090759,\n",
       " 14.64106273651123,\n",
       " 10.616471290588379,\n",
       " 0.0017655928386375308,\n",
       " 0.03384695202112198,\n",
       " 0.0004062606021761894,\n",
       " 0.00013492576545104384,\n",
       " 1.534615397453308,\n",
       " 0.003360724775120616,\n",
       " 0.4115973114967346,\n",
       " 0.2522604465484619,\n",
       " 0.08101014792919159]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model(np.expand_dims(np.array(x), axis=0)).numpy() * 100)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Database Developer'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_unique[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.expand_dims(np.array(convert_to_x(df.iloc[1000])), axis=0)\n",
    "labels[1000].tolist().index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['system developer', 'Business process analyst', 'developer',\n",
       "       'testing', 'security', 'cloud computing'], dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"interested career area \"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Database Developer',\n",
       " 'Portal Administrator',\n",
       " 'Systems Security Administrator',\n",
       " 'Business Systems Analyst',\n",
       " 'Software Systems Engineer',\n",
       " 'Business Intelligence Analyst',\n",
       " 'CRM Technical Developer',\n",
       " 'Mobile Applications Developer',\n",
       " 'UX Designer',\n",
       " 'Quality Assurance Associate',\n",
       " 'Web Developer',\n",
       " 'Information Security Analyst',\n",
       " 'CRM Business Analyst',\n",
       " 'Technical Support',\n",
       " 'Project Manager',\n",
       " 'Information Technology Manager',\n",
       " 'Programmer Analyst',\n",
       " 'Design & UX',\n",
       " 'Solutions Architect',\n",
       " 'Systems Analyst',\n",
       " 'Network Security Administrator',\n",
       " 'Data Architect',\n",
       " 'Software Developer',\n",
       " 'E-Commerce Analyst',\n",
       " 'Technical Services/Help Desk/Tech Support',\n",
       " 'Information Technology Auditor',\n",
       " 'Database Manager',\n",
       " 'Applications Developer',\n",
       " 'Database Administrator',\n",
       " 'Network Engineer',\n",
       " 'Software Engineer',\n",
       " 'Technical Engineer',\n",
       " 'Network Security Engineer',\n",
       " 'Software Quality Assurance (QA) / Testing']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "063da5ec96525b703b2b4b88ba5015678e29341c0c783b18b72decb99d23a1d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
